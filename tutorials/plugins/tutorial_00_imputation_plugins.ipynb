{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "molecular-moscow",
   "metadata": {},
   "source": [
    "# Imputation Plugins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corrected-basis",
   "metadata": {},
   "source": [
    "Missing data is a crucial issue when applying machine learning algorithms to real-world datasets.\n",
    "\n",
    "**AutoPrognosis** provides a set of default imputation plugins using [HyperImpute](https://github.com/vanderschaarlab/hyperimpute) and can be extended with any number of other plugins."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "multiple-annotation",
   "metadata": {},
   "source": [
    "### Plugins 101\n",
    "\n",
    "Every **AutoPrognosis plugin** must implement the **`Plugin`** interface provided by `autoprognosis/plugins/core/base_plugin.py`.\n",
    "\n",
    "Each **AutoPrognosis imputation plugin** must implement the **`ImputerPlugin`** interface provided by `autoprognosis/plugins/imputers/base.py`\n",
    "\n",
    "__Warning__ : If a plugin doesn't override all the abstract methods, it won't be loaded by the library.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "__API__ : Every imputation plugin must implement the following methods:\n",
    "- `name()` - a static method that returns the name of the plugin. e.g., EM, mice, etc.\n",
    "    \n",
    "- `hyperparameter_space()` - a static method that returns the hyperparameters that can be tuned during the optimization. The method will return a list of `skopt.space.Dimension` derived objects.\n",
    "    \n",
    "- `_fit()` - internal implementation, called by the `fit` method.\n",
    "\n",
    "- `_transform()` - internal implementation, called by the `transform` method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "auburn-hygiene",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wanted-point",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stdlib\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "from math import sqrt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tabulate\n",
    "import xgboost as xgb\n",
    "\n",
    "# third party\n",
    "from IPython.display import HTML, display\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "# autoprognosis absolute\n",
    "from autoprognosis.plugins.utils.metrics import RMSE\n",
    "from autoprognosis.plugins.utils.simulate import simulate_nan\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "devoted-console",
   "metadata": {},
   "source": [
    "### Loading the Imputation plugins\n",
    "\n",
    "Make sure that you have installed AutoPrognosis in your workspace.\n",
    "\n",
    "You can do that by running `pip install .` in the root of the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coated-innocent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoprognosis absolute\n",
    "from autoprognosis.plugins.imputers import ImputerPlugin, Imputers\n",
    "\n",
    "imputers = Imputers()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "refined-booth",
   "metadata": {},
   "source": [
    "### List the existing plugins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incident-familiar",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputers.list_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dominican-tulsa",
   "metadata": {},
   "source": [
    "### Testing the performance\n",
    "\n",
    "We simulate some testing datasets using 3 amputation strategies:\n",
    "- **Missing Completely At Random** (MCAR) if the probability of being missing is the same for all observations\n",
    "- **Missing At Random** (MAR) if the probability of being missing only depends on observed values.\n",
    "- **Missing Not At Random** (MNAR) if the unavailability of the data depends on both observed and unobserved data such as its value itself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advance-expert",
   "metadata": {},
   "source": [
    "#### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preceding-vermont",
   "metadata": {},
   "outputs": [],
   "source": [
    "# third party\n",
    "import pandas as pd\n",
    "\n",
    "# autoprognosis absolute\n",
    "from autoprognosis.plugins.preprocessors.feature_scaling.plugin_minmax_scaler import (\n",
    "    plugin as minmax,\n",
    ")\n",
    "\n",
    "preproc = minmax()\n",
    "\n",
    "\n",
    "def dataset():\n",
    "    X, y = load_breast_cancer(return_X_y=True)\n",
    "    X = preproc.fit_transform(X, y).to_numpy()\n",
    "    return train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "\n",
    "def ampute(x, mechanism, p_miss):\n",
    "    x_simulated = simulate_nan(x, p_miss, mechanism)\n",
    "\n",
    "    mask = x_simulated[\"mask\"]\n",
    "    x_miss = x_simulated[\"X_incomp\"]\n",
    "\n",
    "    return x, x_miss, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chief-jimmy",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {}\n",
    "headers = [\"Plugin\"]\n",
    "\n",
    "pct = 0.3\n",
    "\n",
    "mechanisms = [\"MAR\", \"MNAR\", \"MCAR\"]\n",
    "percentages = [pct]\n",
    "\n",
    "plugins = [\"mean\", \"median\"]\n",
    "## Uncomment this for full imputation tests\n",
    "# plugins = imputers.list() #default plugins\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = dataset()\n",
    "\n",
    "for ampute_mechanism in mechanisms:\n",
    "    for p_miss in percentages:\n",
    "        if ampute_mechanism not in datasets:\n",
    "            datasets[ampute_mechanism] = {}\n",
    "\n",
    "        headers.append(ampute_mechanism + \"-\" + str(p_miss))\n",
    "        datasets[ampute_mechanism][p_miss] = ampute(X_train, ampute_mechanism, p_miss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opened-finding",
   "metadata": {},
   "source": [
    "#### Evaluation\n",
    "\n",
    "We compare the methods in terms of root mean squared error (RMSE) to the initial dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recovered-tonight",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "duration = []\n",
    "\n",
    "for plugin in tqdm(plugins):\n",
    "    plugin_results = [plugin]\n",
    "    plugin_duration = [plugin]\n",
    "\n",
    "    for ampute_mechanism in mechanisms:\n",
    "        for p_miss in percentages:\n",
    "            ctx = imputers.get(plugin)\n",
    "            x, x_miss, mask = datasets[ampute_mechanism][p_miss]\n",
    "\n",
    "            start = time.time() * 1000\n",
    "            x_imp = ctx.fit_transform(pd.DataFrame(x_miss))\n",
    "\n",
    "            plugin_duration.append(round(time.time() * 1000 - start, 4))\n",
    "            plugin_results.append(RMSE(x_imp.to_numpy(), x, mask))\n",
    "\n",
    "    results.append(plugin_results)\n",
    "    duration.append(plugin_duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "narrative-amount",
   "metadata": {},
   "source": [
    "### Reconstruction error(RMSE)\n",
    "\n",
    "__Interpretation__ : The following table shows the reconstruction error -  the __Root Mean Square Error(RMSE)__ for each method applied on the original full dataset and the imputed dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "normal-decline",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(HTML(tabulate.tabulate(results, headers=headers, tablefmt=\"html\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overhead-favor",
   "metadata": {},
   "source": [
    "### XGBoost test score after imputation\n",
    "\n",
    "__Interpretation__ The following table shows different metrics on the test set for an XGBoost classifier, after imputing the dataset with each method.\n",
    "Metrics:\n",
    " - accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nonprofit-content",
   "metadata": {},
   "outputs": [],
   "source": [
    "# third party\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "def get_metrics(X_train, y_train, X_test, y_test):\n",
    "    xgb_clf = xgb.XGBClassifier(verbosity=0)\n",
    "    xgb_clf = xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = xgb_clf.predict(X_test)\n",
    "\n",
    "    score = xgb_clf.score(X_test, y_test)\n",
    "\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred)\n",
    "    auroc = metrics.auc(fpr, tpr)\n",
    "\n",
    "    prec, recall, thresholds = metrics.precision_recall_curve(y_test, y_pred)\n",
    "    aurpc = metrics.auc(recall, prec)\n",
    "\n",
    "    return score, auroc, aurpc\n",
    "\n",
    "\n",
    "metrics_headers = [\"Plugin\", \"Accuracy\", \"AUROC\", \"AURPC\"]\n",
    "xgboost_test_score = []\n",
    "\n",
    "\n",
    "x, x_miss, mask = datasets[\"MAR\"][pct]\n",
    "\n",
    "xgboost_test_score.append(\n",
    "    [\"original dataset\", *get_metrics(X_train, y_train, X_test, y_test)]\n",
    ")\n",
    "\n",
    "for plugin in plugins:\n",
    "    X_train_imp = imputers.get(plugin).fit_transform(pd.DataFrame(x_miss.copy()))\n",
    "\n",
    "    score, auroc, aurpc = get_metrics(X_train_imp, y_train, X_test, y_test)\n",
    "\n",
    "    xgboost_test_score.append([plugin, score, auroc, aurpc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77086d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\n",
    "    HTML(\n",
    "        tabulate.tabulate(xgboost_test_score, headers=metrics_headers, tablefmt=\"html\")\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numeric-million",
   "metadata": {},
   "source": [
    "### Duration(ms) results\n",
    "\n",
    "__Info__ : Here we measure the duration of imputing the dataset with each method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viral-suggestion",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(HTML(tabulate.tabulate(duration, headers=headers, tablefmt=\"html\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "earlier-description",
   "metadata": {},
   "source": [
    "## Debugging\n",
    "\n",
    "AutoPrognosis supports **debug** logging. __WARNING__: Don't use it for release builds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "constitutional-toyota",
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoprognosis absolute\n",
    "from autoprognosis import logger\n",
    "\n",
    "imputers = Imputers()\n",
    "\n",
    "logger.add(sink=sys.stderr, level=\"DEBUG\")\n",
    "\n",
    "x, x_miss, mask = datasets[\"MAR\"][pct]\n",
    "\n",
    "x_imp = imputers.get(\"EM\").fit_transform(pd.DataFrame(x))\n",
    "\n",
    "imputers.get(\"softimpute\").fit_transform(pd.DataFrame(x_miss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neural-dutch",
   "metadata": {},
   "source": [
    "# Congratulations!\n",
    "\n",
    "Congratulations on completing this notebook tutorial! If you enjoyed this and would like to join the movement towards Machine learning and AI for medicine, you can do so in the following ways!\n",
    "\n",
    "### Star AutoPrognosis on GitHub\n",
    "\n",
    "The easiest way to help our community is just by starring the Repos! This helps raise awareness of the tools we're building.\n",
    "\n",
    "- [Star AutoPrognosis](https://github.com/vanderschaarlab/autoprognosis)\n",
    "- [Star HyperImpute](https://github.com/vanderschaarlab/hyperimpute)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037f0841",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
